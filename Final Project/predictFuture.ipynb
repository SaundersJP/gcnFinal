{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import heapq\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still Chugging 1999 Dataset Node: 1000\n",
      "Still Chugging 1999 Dataset Node: 2000\n",
      "Still Chugging 1999 Dataset Node: 3000\n",
      "Still Chugging 1999 Dataset Node: 4000\n",
      "Still Chugging 1999 Dataset Node: 5000\n",
      "Still Chugging 1999 Dataset Node: 6000\n",
      "Still Chugging 1999 Dataset Node: 7000\n",
      "Still Chugging 1999 Dataset Node: 8000\n",
      "Still Chugging 1999 Dataset Node: 9000\n",
      "Still Chugging 1999 Dataset Node: 10000\n",
      "Still Chugging 1999 Dataset Node: 11000\n",
      "Still Chugging 1999 Dataset Node: 12000\n",
      "Still Chugging 1999 Dataset Node: 13000\n",
      "Still Chugging 1999 Dataset Node: 14000\n",
      "Still Chugging 1999 Dataset Node: 15000\n",
      "Still Chugging 1999 Dataset Node: 16000\n"
     ]
    }
   ],
   "source": [
    "def nonedges(G,u):\n",
    "    for v in nx.non_neighbors(G,u):\n",
    "        yield (u,v)\n",
    "\n",
    "probability = np.array([0,0,0,0,0,0,0,0,0,1])\n",
    "\n",
    "\n",
    "###########################################################\n",
    "\n",
    "G_1999 = nx.read_edgelist(\"conda_1999.txt\")\n",
    "\n",
    "Gtest_1999 = []\n",
    "for edge in G_1999.edges():\n",
    "    choice = np.random.choice(probability)\n",
    "    if choice == 1:\n",
    "        Gtest_1999.append(edge)\n",
    "for u,v in Gtest_1999:\n",
    "    G_1999.remove_edge(u,v)\n",
    "    \n",
    "i=0\n",
    "topNK1999 = {}\n",
    "for u in G_1999.nodes():\n",
    "    #predictions = nx.adamic_adar_index(G_1999, nonedges(G_1999,u))\n",
    "    predictions = nx.jaccard_coefficient(G_1999, nonedges(G_1999, u))\n",
    "    topN = heapq.nlargest(iterable=predictions, n=25, key=lambda x: x[2])\n",
    "    for field in topN:\n",
    "        topNK1999[(field[0],field[1])] = field[2]\n",
    "    i = i+1\n",
    "    if i%1000 ==0:\n",
    "        print(\"Still Chugging 1999 Dataset Node: \" + str(i))    \n",
    "\n",
    "sortedEdges1999 = sorted(topNK1999.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    \n",
    "with open(\"predict_jaccard_1999.json\", 'w') as outfile:\n",
    "    json.dump(sortedEdges1999, outfile)\n",
    "\n",
    "with open(\"Gtest_jaccard_1999.json\", 'w') as outfile:\n",
    "    json.dump(Gtest_1999, outfile)\n",
    "    \n",
    "# #####################################################    \n",
    "# G_2003 = nx.read_edgelist(\"conda_2003.txt\")\n",
    "\n",
    "\n",
    "# Gtest_2003 = []\n",
    "# for edge in G_2003.edges():\n",
    "#     choice = np.random.choice(probability)\n",
    "#     if choice == 1:\n",
    "#         Gtest_2003.append(edge)\n",
    "# for u,v in Gtest_2003:\n",
    "#     G_2003.remove_edge(u,v)\n",
    "\n",
    "# j=0\n",
    "# topNK2003 = {}\n",
    "# for u in G_2003.nodes():\n",
    "    \n",
    "#     #predictions = nx.adamic_adar_index(G_2003, nonedges(G_2003,u))\n",
    "#     predictions = nx.jaccard_coefficient(G_2003, nonedges(G2003, u))\n",
    "#     topN = heapq.nlargest(iterable=predictions, n=25, key=lambda x: x[2])\n",
    "#     for field in topN:\n",
    "#         topNK2003[(field[0],field[1])] = field[2]\n",
    "#     j = j+1\n",
    "#     if j%1000==0:\n",
    "#         print(\"Still Chugging 2003 Dataset Node: \" + str(j))\n",
    "        \n",
    "# sortedEdges2003 = sorted(topNK2003.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "# with open(\"predict2003.json\", 'w') as outfile:\n",
    "#     json.dump(sortedEdges2003, outfile)\n",
    "# with open(\"Gtest_2003.json\", 'w') as outfile:\n",
    "#     json.dump(Gtest_2003, outfile)\n",
    "    \n",
    "# #####################################################\n",
    "\n",
    "# G_2005 = nx.read_edgelist(\"conda_2005.txt\")\n",
    "\n",
    "\n",
    "# Gtest_2005 = []\n",
    "# for edge in G_2005.edges():\n",
    "#     choice = np.random.choice(probability)\n",
    "#     if choice == 1:\n",
    "#         Gtest_2005.append(edge)\n",
    "# for u,v in Gtest_2005:\n",
    "#     G_2005.remove_edge(u,v)\n",
    "\n",
    "# l = 0\n",
    "# topNK2005 = {}\n",
    "# for u in G_2005.nodes():\n",
    "    \n",
    "#     #predictions = nx.adamic_adar_index(G_2005, nonedges(G_2005,u))\n",
    "#     predictions = nx.jaccard_coefficient(G_2005, nonedges(G_2005,u))\n",
    "#     topN = heapq.nlargest(iterable=predictions, n=25, key=lambda x: x[2])\n",
    "#     for field in topN:\n",
    "#         topNK2005[(field[0],field[1])] = field[2]\n",
    "#     l = l+1\n",
    "#     if l%1000==0:\n",
    "#         print(\"Still Chugging 2005 Dataset Node: \" + str(l))\n",
    "        \n",
    "# sortedEdges2005 = sorted(topNK2005.items(), key=lambda kv: kv[1], reverse=True)\n",
    "# with open(\"predict2005.json\", 'w') as outfile:\n",
    "#     json.dump(sortedEdges2005, outfile)\n",
    "# with open(\"Gtest_2005.json\", 'w') as outfile:\n",
    "#     json.dump(Gtest_2005, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy for 1999 Jaccard: 0.21752010156580617\n"
     ]
    }
   ],
   "source": [
    "preds1999 = None\n",
    "gtest1999 = None\n",
    "with open(\"Gtest_jaccard_1999.json\",\"r\") as infile:\n",
    "    gtest1999 = json.load(infile)\n",
    "with open(\"predict_jaccard_1999.json\",\"r\") as infile:\n",
    "    preds1999 = json.load(infile)\n",
    "    \n",
    "topN1999 = heapq.nlargest(iterable=preds1999, n=(2*len(gtest1999)), key = lambda x:x[1])\n",
    "count1999 = 0\n",
    "for i in range(0,len(topN1999),2):\n",
    "    if((topN1999[i][0] in gtest1999) or (topN1999[i+1][0] in gtest1999)):\n",
    "        count1999 += 1\n",
    "        \n",
    "print(\"Prediction accuracy for 1999 Jaccard: \" + str(count1999/len(gtest1999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
