{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import heapq\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42754\n"
     ]
    }
   ],
   "source": [
    "def nonedges(G,u):\n",
    "    for v in nx.non_neighbors(G,u):\n",
    "        yield (u,v)\n",
    "\n",
    "probability = np.array([0,0,0,0,0,0,0,0,0,1])\n",
    "\n",
    "\n",
    "###########################################################\n",
    "\n",
    "G_1999 = nx.read_edgelist(\"conda_1999.txt\")\n",
    "\n",
    "Gtest_1999 = []\n",
    "for edge in G_1999.edges():\n",
    "    choice = np.random.choice(probability)\n",
    "    if choice == 1:\n",
    "        Gtest_1999.append(edge)\n",
    "for u,v in Gtest_1999:\n",
    "    G_1999.remove_edge(u,v)\n",
    "    \n",
    "i=0\n",
    "topNK1999 = {}\n",
    "for u in G_1999.nodes():\n",
    "    #predictions = nx.adamic_adar_index(G_1999, nonedges(G_1999,u))\n",
    "    predictions = nx.jaccard_coefficient(G_1999, nonedges(G_1999, u))\n",
    "    topN = heapq.nlargest(iterable=predictions, n=25, key=lambda x: x[2])\n",
    "    for field in topN:\n",
    "        topNK1999[(field[0],field[1])] = field[2]\n",
    "    i = i+1\n",
    "    if i%1000 ==0:\n",
    "        print(\"Still Chugging 1999 Dataset Node: \" + str(i))    \n",
    "\n",
    "sortedEdges1999 = sorted(topNK1999.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    \n",
    "with open(\"predict1999.json\", 'w') as outfile:\n",
    "    json.dump(sortedEdges1999, outfile)\n",
    "\n",
    "with open(\"Gtest_1999.json\", 'w') as outfile:\n",
    "    json.dump(Gtest_1999, outfile)\n",
    "    \n",
    "#####################################################    \n",
    "G_2003 = nx.read_edgelist(\"conda_2003.txt\")\n",
    "\n",
    "\n",
    "Gtest_2003 = []\n",
    "for edge in G_2003.edges():\n",
    "    choice = np.random.choice(probability)\n",
    "    if choice == 1:\n",
    "        Gtest_2003.append(edge)\n",
    "for u,v in Gtest_2003:\n",
    "    G_2003.remove_edge(u,v)\n",
    "\n",
    "j=0\n",
    "topNK2003 = {}\n",
    "for u in G_2003.nodes():\n",
    "    \n",
    "    #predictions = nx.adamic_adar_index(G_2003, nonedges(G_2003,u))\n",
    "    predictions = nx.jaccard_coefficient(G_2003, nonedges(G2003, u))\n",
    "    topN = heapq.nlargest(iterable=predictions, n=25, key=lambda x: x[2])\n",
    "    for field in topN:\n",
    "        topNK2003[(field[0],field[1])] = field[2]\n",
    "    j = j+1\n",
    "    if j%1000==0:\n",
    "        print(\"Still Chugging 2003 Dataset Node: \" + str(j))\n",
    "        \n",
    "sortedEdges2003 = sorted(topNK2003.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "with open(\"predict2003.json\", 'w') as outfile:\n",
    "    json.dump(sortedEdges2003, outfile)\n",
    "with open(\"Gtest_2003.json\", 'w') as outfile:\n",
    "    json.dump(Gtest_2003, outfile)\n",
    "    \n",
    "#####################################################\n",
    "\n",
    "G_2005 = nx.read_edgelist(\"conda_2005.txt\")\n",
    "\n",
    "\n",
    "Gtest_2005 = []\n",
    "for edge in G_2005.edges():\n",
    "    choice = np.random.choice(probability)\n",
    "    if choice == 1:\n",
    "        Gtest_2005.append(edge)\n",
    "for u,v in Gtest_2005:\n",
    "    G_2005.remove_edge(u,v)\n",
    "\n",
    "l = 0\n",
    "topNK2005 = {}\n",
    "for u in G_2005.nodes():\n",
    "    \n",
    "    #predictions = nx.adamic_adar_index(G_2005, nonedges(G_2005,u))\n",
    "    predictions = nx.jaccard_coefficient(G_2005, nonedges(G_2005,u))\n",
    "    topN = heapq.nlargest(iterable=predictions, n=25, key=lambda x: x[2])\n",
    "    for field in topN:\n",
    "        topNK2005[(field[0],field[1])] = field[2]\n",
    "    l = l+1\n",
    "    if l%1000==0:\n",
    "        print(\"Still Chugging 2005 Dataset Node: \" + str(l))\n",
    "        \n",
    "sortedEdges2005 = sorted(topNK2005.items(), key=lambda kv: kv[1], reverse=True)\n",
    "with open(\"predict2005.json\", 'w') as outfile:\n",
    "    json.dump(sortedEdges2005, outfile)\n",
    "with open(\"Gtest_2005.json\", 'w') as outfile:\n",
    "    json.dump(Gtest_2005, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
